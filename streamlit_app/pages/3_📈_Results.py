"""
Ridge MMM - Results & Analysis Page
Comprehensive dashboard for model results and insights
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import sys
from pathlib import Path
import io
from datetime import datetime

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from ridge_mmm import RidgeMMM
from visualizations import (
    plot_waterfall,
    plot_decomposition,
    plot_response_curves,
    plot_actual_vs_predicted,
    plot_residuals,
    plot_channel_contributions,
    plot_qq
)
from utils import format_currency

# Cached visualization functions for performance
@st.cache_data(show_spinner=False)
def cached_plot_actual_vs_predicted(y_true, y_pred):
    """Cached version of plot_actual_vs_predicted."""
    return plot_actual_vs_predicted(y_true, y_pred)

@st.cache_data(show_spinner=False)
def cached_plot_residuals(y_true, y_pred):
    """Cached version of plot_residuals."""
    return plot_residuals(y_true, y_pred)

@st.cache_data(show_spinner=False)
def cached_plot_waterfall(_contributions_df):
    """Cached version of plot_waterfall."""
    return plot_waterfall(_contributions_df)

@st.cache_data(show_spinner=False)
def cached_plot_channel_contributions(_contributions_df):
    """Cached version of plot_channel_contributions."""
    return plot_channel_contributions(_contributions_df)

@st.cache_data(show_spinner=False)
def cached_plot_decomposition(_decomp_df):
    """Cached version of plot_decomposition."""
    return plot_decomposition(_decomp_df)

@st.cache_data(show_spinner=False)
def cached_plot_response_curves(_mmm, _X, channels):
    """Cached version of plot_response_curves."""
    return plot_response_curves(_mmm, _X, channels)

@st.cache_data(show_spinner=False)
def cached_plot_qq(residuals):
    """Cached version of plot_qq."""
    return plot_qq(residuals)

# Page configuration
st.set_page_config(
    page_title="Results & Analysis - Ridge MMM",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# Custom CSS
st.markdown("""
    <style>
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
    }
    .success-card {
        background-color: #d4edda;
        border-left-color: #28a745;
    }
    .warning-card {
        background-color: #fff3cd;
        border-left-color: #ffc107;
    }
    </style>
""", unsafe_allow_html=True)

# Header
st.title("ğŸ“ˆ Results & Analysis")
st.markdown("ë§ˆì¼€íŒ… ë¯¹ìŠ¤ ëª¨ë¸ì˜ ì¢…í•© ë¶„ì„")

# Check if model is trained
if not st.session_state.get('model_trained', False):
    st.warning("âš ï¸ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € Model Configuration í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
    st.stop()

# Get model and data from session state
mmm = st.session_state.mmm_model
df = st.session_state.df
config = st.session_state.config
train_metrics = st.session_state.train_metrics
test_metrics = st.session_state.test_metrics

# Get configuration
date_col = config.get('date_column')
revenue_col = config.get('revenue_column')
media_columns = config.get('media_columns', [])
exog_cols = config.get('exog_columns', [])

# Prepare data
train_split = st.session_state.transformation_config['train_test_split']
train_size = int(len(df) * train_split)

feature_cols = media_columns + exog_cols
X = df[feature_cols]
y = df[revenue_col]

X_train = X.iloc[:train_size]
y_train = y.iloc[:train_size]
X_test = X.iloc[train_size:]
y_test = y.iloc[train_size:]

# Get predictions
y_train_pred = mmm.predict(X_train)
y_test_pred = mmm.predict(X_test)

# ============================================================================
# SIDEBAR: FILTERS AND DOWNLOADS
# ============================================================================

with st.sidebar:
    st.markdown("### ğŸ“Š Results Dashboard")
    st.markdown("---")
    
    st.markdown("### ğŸ¯ Model Summary")
    summary = mmm.get_model_summary()
    st.write(f"**Channels**: {summary['n_channels']}")
    st.write(f"**Features**: {summary['n_features']}")
    st.write(f"**Alpha**: {summary['alpha']}")
    
    st.markdown("---")
    st.markdown("### ğŸ“¥ Downloads")
    
    # Download Results as Excel
    if st.button("ğŸ“Š Download Results (Excel)", use_container_width=True):
        with st.spinner("Generating Excel file..."):
            try:
                # Create Excel writer
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    # Metrics sheet
                    metrics_df = pd.DataFrame({
                        'Metric': ['RÂ²', 'MAPE', 'MAE', 'RMSE'],
                        'Train': [
                            train_metrics['r2'],
                            train_metrics['mape'],
                            train_metrics['mae'],
                            train_metrics['rmse']
                        ],
                        'Test': [
                            test_metrics['r2'],
                            test_metrics['mape'],
                            test_metrics['mae'],
                            test_metrics['rmse']
                        ]
                    })
                    metrics_df.to_excel(writer, sheet_name='Metrics', index=False)
                    
                    # Contributions sheet
                    contributions = mmm.get_contributions(X)
                    contributions.to_excel(writer, sheet_name='Contributions', index=False)
                    
                    # Decomposition sheet
                    decomp = mmm.decompose_timeseries(X, y)
                    decomp.to_excel(writer, sheet_name='Decomposition', index=False)
                    
                    # Model summary sheet
                    summary_df = pd.DataFrame([
                        {'Parameter': 'Alpha', 'Value': summary['alpha']},
                        {'Parameter': 'Channels', 'Value': ', '.join(summary['channels'])},
                        {'Parameter': 'Features', 'Value': summary['n_features']},
                        {'Parameter': 'Intercept', 'Value': summary['intercept']}
                    ])
                    summary_df.to_excel(writer, sheet_name='Model Summary', index=False)
                
                output.seek(0)
                
                st.download_button(
                    label="â¬‡ï¸ Download Excel",
                    data=output,
                    file_name=f"mmm_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
            except Exception as e:
                st.error(f"Error generating Excel: {str(e)}")
    
    st.markdown("---")
    st.markdown("### ğŸ’¡ Quick Insights")
    
    # Calculate quick insights
    contributions = mmm.get_contributions(X)
    top_channel = contributions[contributions['channel'] != 'base'].nlargest(1, 'contribution')
    
    if not top_channel.empty:
        st.success(f"**Top Channel**: {top_channel.iloc[0]['channel']}")
        st.write(f"ROAS: {top_channel.iloc[0]['roas']:.2f}")
        st.write(f"Contribution: {format_currency(top_channel.iloc[0]['contribution'])}")

# ============================================================================
# MAIN CONTENT: TABS
# ============================================================================

# ============================================================================
# MAIN CONTENT: TABS
# ============================================================================

# Check if hierarchical model with multiple segments
is_hierarchical = hasattr(mmm, 'analysis_level') and mmm.analysis_level != 'global'

tabs_list = [
    "ğŸ“Š Model Performance",
    "ğŸ’° Channel Contributions",
    "ğŸ“ˆ Time Series Decomposition",
    "ğŸ“‰ Response Curves",
    "ğŸ” Model Diagnostics"
]

if is_hierarchical:
    tabs_list.insert(0, "ğŸŒ Market Comparison")

tabs = st.tabs(tabs_list)

if is_hierarchical:
    market_tab = tabs[0]
    perf_tab = tabs[1]
    contrib_tab = tabs[2]
    decomp_tab = tabs[3]
    curve_tab = tabs[4]
    diag_tab = tabs[5]
else:
    perf_tab = tabs[0]
    contrib_tab = tabs[1]
    decomp_tab = tabs[2]
    curve_tab = tabs[3]
    diag_tab = tabs[4]

# ============================================================================
# TAB: MARKET COMPARISON (NEW)
# ============================================================================

if is_hierarchical:
    with market_tab:
        st.markdown("## ğŸŒ Market Comparison")
        st.markdown("Compare performance across different markets/segments")
        
        # Comparison table
        st.markdown("### Segment Performance Comparison")
        comparison_df = mmm.compare_segments(df, metric='roas')
        
        # Format for display
        display_comp = comparison_df.copy()
        display_comp['roas'] = display_comp['roas'].apply(lambda x: f"{x:.2f}")
        display_comp['spend'] = display_comp['spend'].apply(lambda x: format_currency(x, decimals=0))
        display_comp['revenue'] = display_comp['revenue'].apply(lambda x: format_currency(x, decimals=0))
        
        st.dataframe(display_comp, use_container_width=True, hide_index=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Visualization: ROAS by market (bar chart)
            import plotly.express as px
            fig_roas = px.bar(comparison_df, x='segment', y='roas', 
                         color='roas', color_continuous_scale='RdYlGn',
                         title='ROAS by Market Segment')
            st.plotly_chart(fig_roas, use_container_width=True)
            
        with col2:
            # Channel performance heatmap
            # We need to construct heatmap data: Rows=Markets, Cols=Channels, Values=ROAS
            
            heatmap_data = []
            segments = mmm.models.keys()
            
            for seg in segments:
                if seg == 'global': continue
                contribs = mmm.models[seg].get_contributions(df[df['country'] == seg] if mmm.analysis_level == 'country' else df) 
                # Note: The df filtering above is a bit simplistic, ideally get_contributions handles it if we pass the right df subset
                # But mmm.models[seg] is a RidgeMMM trained on that segment.
                # We should probably use the helper in HierarchicalMMM but it aggregates.
                # Let's manually extract from models for the heatmap.
                
                # Actually, we can just iterate and call get_contributions on the subset
                # But we don't have the subset easily here without filtering df again.
                # Let's try to use the model's internal data if possible? No.
                # Let's filter df based on segment.
                
                seg_df = pd.DataFrame()
                if mmm.analysis_level == 'country':
                    seg_df = df[df['country'] == seg]
                elif mmm.analysis_level == 'os':
                    seg_df = df[df['os'] == seg]
                elif mmm.analysis_level == 'country_os':
                    # This is harder to filter without the composite key
                    c, o = seg.split('_')
                    seg_df = df[(df['country'] == c) & (df['os'] == o)]
                
                if not seg_df.empty:
                    c_df = mmm.models[seg].get_contributions(seg_df)
                    for _, row in c_df.iterrows():
                        if row['channel'] != 'base':
                            heatmap_data.append({
                                'Market': seg,
                                'Channel': row['channel'],
                                'ROAS': row['roas']
                            })
            
            if heatmap_data:
                heatmap_df = pd.DataFrame(heatmap_data)
                # Pivot for imshow
                heatmap_pivot = heatmap_df.pivot(index='Market', columns='Channel', values='ROAS')
                
                fig_heatmap = px.imshow(heatmap_pivot, 
                                text_auto='.2f',
                                color_continuous_scale='RdYlGn',
                                title="Channel ROAS Heatmap")
                st.plotly_chart(fig_heatmap, use_container_width=True)

        # Cross-market insights
        st.markdown("### ğŸ” Cross-Market Insights")
        insights = mmm.get_cross_market_insights()
        
        if insights:
            col1, col2 = st.columns(2)
            with col1:
                st.info("**Best Performing Channels:**")
                for mkt, ch in insights.get('best_channels', {}).items():
                    st.write(f"- **{mkt}**: {ch}")
            
            with col2:
                # Placeholder for other insights
                pass
        else:
            st.info("No insights available.")

# ============================================================================
# TAB 1: MODEL PERFORMANCE
# ============================================================================

with perf_tab:
    st.markdown("## ğŸ“Š Model Performance")
    st.markdown("ë§ˆê·¸ë°ì´í„°ì— ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”")
    
    # Display metrics
    st.markdown("### Training Set Performance")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "RÂ² Score",
            f"{train_metrics['r2']:.4f}",
            help="ê²°ì •ê³„ìˆ˜ (0-1, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)"
        )
    
    with col2:
        st.metric(
            "MAPE",
            f"{train_metrics['mape']:.2f}%",
            help="í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)"
        )
    
    with col3:
        st.metric(
            "MAE",
            format_currency(train_metrics['mae'], decimals=0),
            help="í‰ê·  ì ˆëŒ€ ì˜¤ì°¨"
        )
    
    with col4:
        st.metric(
            "RMSE",
            format_currency(train_metrics['rmse'], decimals=0),
            help="í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨"
        )
    
    st.markdown("### Test Set Performance")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        delta_r2 = test_metrics['r2'] - train_metrics['r2']
        st.metric(
            "RÂ² Score",
            f"{test_metrics['r2']:.4f}",
            delta=f"{delta_r2:.4f}",
            delta_color="normal"
        )
    
    with col2:
        delta_mape = test_metrics['mape'] - train_metrics['mape']
        st.metric(
            "MAPE",
            f"{test_metrics['mape']:.2f}%",
            delta=f"{delta_mape:.2f}%",
            delta_color="inverse"
        )
    
    with col3:
        st.metric(
            "MAE",
            format_currency(test_metrics['mae'], decimals=0)
        )
    
    with col4:
        st.metric(
            "RMSE",
            format_currency(test_metrics['rmse'], decimals=0)
        )
    
    # Interpretation
    if test_metrics['r2'] > 0.8:
        st.success("âœ… ìš°ìˆ˜í•œ ëª¨ë¸ ì í•©ë„! RÂ² > 0.8ì€ ê°•ë ¥í•œ ì˜ˆì¸¡ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
    elif test_metrics['r2'] > 0.6:
        st.info("âœ“ ì–‘í˜¸í•œ ëª¨ë¸ ì í•©ë„. RÂ² > 0.6ì€ í•©ë¦¬ì ì¸ ì˜ˆì¸¡ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ ëª¨ë¸ ì í•©ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³€í™˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")
    
    st.markdown("---")
    
    # Actual vs Predicted plot
    st.markdown("### Actual vs Predicted Revenue")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Combine train and test for full view
        y_all = np.concatenate([y_train, y_test])
        y_pred_all = np.concatenate([y_train_pred, y_test_pred])

        fig_actual_pred = cached_plot_actual_vs_predicted(y_all, y_pred_all)
        st.plotly_chart(fig_actual_pred, use_container_width=True)
    
    with col2:
        st.markdown("#### í•´ì„")
        st.markdown("""
        **í™•ì¸í•  ì‚¬í•­:**
        - ë¹¨ê°„ ì„ ì— ê°€ê¹Œìš´ ì ë“¤ì€ ì •í™•í•œ ì˜ˆì¸¡ì„ ë‚˜íƒ€ëƒ„
        - ìƒ‰ìƒ ê°•ë„ëŠ” ì˜ˆì¸¡ ì˜¤ì°¨ì˜ í¬ê¸°ë¥¼ ë³´ì—¬ì¤Œ
        - ì²´ê³„ì ì¸ í¸ì°¨ëŠ” ëª¨ë¸ í¸í–¥ì„ ì‹œì‚¬í•¨
        
        **ì¢‹ì€ ì‹ í˜¸:**
        - ì ë“¤ì´ ì„  ì£¼ë³€ì— ê³ ë¥´ê²Œ ë¶„í¬
        - ì”ì°¨ì— ëª…í™•í•œ íŒ¨í„´ì´ ì—†ìŒ
        - RÂ²ê°€ 1.0ì— ê°€ê¹Œì›€
        """)
    
    st.markdown("---")
    
    # Residual Analysis
    st.markdown("### Residual Analysis")

    fig_residuals = cached_plot_residuals(y_all, y_pred_all)
    st.plotly_chart(fig_residuals, use_container_width=True)
    
    st.info("""
    **ì”ì°¨ í”Œë¡¯ìœ¼ë¡œ ì‹ë³„í•  ìˆ˜ ìˆëŠ” ê²ƒ:**
    - **ì™¼ìª½ í”Œë¡¯**: íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”. ë¬´ì‘ìœ„ ì‚°ì ì´ ì¢‹ìœ¼ë©°, íŒ¨í„´ì€ ëª¨ë¸ ë¬¸ì œë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤.
    - **ì˜¤ë¥¸ìª½ í”Œë¡¯**: ì •ê·œ ë¶„í¬ì™€ ìœ ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤. í¸ì°¨ëŠ” ë¹„ì •ê·œ ì˜¤ì°¨ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤.
    """)

# ============================================================================
# TAB 2: CHANNEL CONTRIBUTIONS
# ============================================================================

with contrib_tab:
    st.markdown("## ğŸ’° Channel Contributions")
    st.markdown("ê° ì±„ë„ì´ ìˆ˜ìµì— ì–´ë–»ê²Œ ê¸°ì—¬í•˜ëŠ”ì§€ ì´í•´í•˜ì„¸ìš”")
    
    # Get contributions
    contributions = mmm.get_contributions(X)
    
    # Display contributions table
    st.markdown("### Contribution Summary")
    
    # Format table
    display_df = contributions.copy()
    display_df['spend'] = display_df['spend'].apply(lambda x: format_currency(x, decimals=0))
    display_df['contribution'] = display_df['contribution'].apply(lambda x: format_currency(x, decimals=0))
    display_df['roas'] = display_df['roas'].apply(lambda x: f"{x:.2f}")
    display_df['contribution_pct'] = display_df['contribution_pct'].apply(lambda x: f"{x:.1f}%")
    
    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True
    )
    
    st.markdown("---")
    
    # Waterfall chart
    st.markdown("### Revenue Decomposition (Waterfall)")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig_waterfall = cached_plot_waterfall(contributions)
        st.plotly_chart(fig_waterfall, use_container_width=True)
    
    with col2:
        st.markdown("#### ì°¨íŠ¸ ì½ëŠ” ë°©ë²•")
        st.markdown("""
        **ì›Œí„°í´ ì°¨íŠ¸ê°€ ë³´ì—¬ì£¼ëŠ” ê²ƒ:**
        - **Base**: ë§ˆì¼€íŒ… ì—†ì´ ë°œìƒí•˜ëŠ” ìˆ˜ìµ
        - **ê° ì±„ë„**: ì¦ë¶„ ê¸°ì—¬ë„
        - **Total**: ëª¨ë“  êµ¬ì„± ìš”ì†Œì˜ í•©ê³„
        
        **ì¸ì‚¬ì´íŠ¸:**
        - ë§‰ëŒ€ê°€ ë†’ì„ìˆ˜ë¡ = ì˜í–¥ë ¥ì´ í¼
        - ì±„ë„ ë†’ì´ ë¹„êµ
        - BaseëŠ” ìì—° ë°œìƒ ìˆ˜ìµì„ ë³´ì—¬ì¤Œ
        """)
    
    st.markdown("---")
    
    # Horizontal bar chart
    st.markdown("### Channel Contributions (Ranked)")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig_bars = cached_plot_channel_contributions(contributions)
        st.plotly_chart(fig_bars, use_container_width=True)
    
    with col2:
        st.markdown("#### ROAS ìƒ‰ìƒ ì½”ë“œ")
        st.markdown("""
        - ğŸŸ¢ **ë…¹ìƒ‰**: ROAS â‰¥ 3.0 (ìš°ìˆ˜)
        - ğŸŸ¡ **ì£¼í™©ìƒ‰**: 2.0 â‰¤ ROAS < 3.0 (ì–‘í˜¸)
        - ğŸ”´ **ë¹¨ê°„ìƒ‰**: ROAS < 2.0 (ê°œì„  í•„ìš”)
        
        **ROAS** = ê´‘ê³  íˆ¬ì ëŒ€ë¹„ ìˆ˜ìµë¥ 
        
        ROASê°€ ë†’ì„ìˆ˜ë¡ íš¨ìœ¨ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤.
        """)
    
    # Key insights
    st.markdown("---")
    st.markdown("### ğŸ’¡ Key Insights")
    
    # Calculate insights
    channel_contribs = contributions[contributions['channel'] != 'base']
    total_spend = channel_contribs['spend'].sum()
    total_contribution = channel_contribs['contribution'].sum()
    overall_roas = total_contribution / total_spend if total_spend > 0 else 0
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "Total Marketing Spend",
            format_currency(total_spend, decimals=0)
        )
    
    with col2:
        st.metric(
            "Total Marketing Contribution",
            format_currency(total_contribution, decimals=0)
        )
    
    with col3:
        st.metric(
            "Overall ROAS",
            f"{overall_roas:.2f}"
        )

# ============================================================================
# TAB 3: TIME SERIES DECOMPOSITION
# ============================================================================

with decomp_tab:
    st.markdown("## ğŸ“ˆ Time Series Decomposition")
    st.markdown("ê° ì±„ë„ì´ ì‹œê°„ì— ë”°ë¼ ì–´ë–»ê²Œ ê¸°ì—¬í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    
    # Get decomposition
    decomp = mmm.decompose_timeseries(X, y)
    
    # Date range filter
    if 'date' in decomp.columns:
        st.markdown("### Filter by Date Range")
        
        col1, col2 = st.columns(2)
        
        with col1:
            min_date = pd.to_datetime(decomp['date']).min()
            max_date = pd.to_datetime(decomp['date']).max()
            
            start_date = st.date_input(
                "Start Date",
                value=min_date,
                min_value=min_date,
                max_value=max_date
            )
        
        with col2:
            end_date = st.date_input(
                "End Date",
                value=max_date,
                min_value=min_date,
                max_value=max_date
            )
        
        # Filter decomposition
        decomp_filtered = decomp[
            (pd.to_datetime(decomp['date']) >= pd.to_datetime(start_date)) &
            (pd.to_datetime(decomp['date']) <= pd.to_datetime(end_date))
        ]
    else:
        decomp_filtered = decomp
    
    st.markdown("---")
    
    # Decomposition chart
    st.markdown("### Revenue Decomposition Over Time")

    fig_decomp = cached_plot_decomposition(decomp_filtered)
    st.plotly_chart(fig_decomp, use_container_width=True)
    
    st.info("""
    **ì°¨íŠ¸ ì½ëŠ” ë°©ë²•:**
    - ê° ìƒ‰ìƒ ì˜ì—­ì€ ì±„ë„ì˜ ê¸°ì—¬ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
    - ìŠ¤íƒì€ ì´ ì˜ˆì¸¡ ìˆ˜ìµì„ ë³´ì—¬ì¤ë‹ˆë‹¤
    - ê²€ì€ìƒ‰ ì ì„ ì€ ì‹¤ì œ ìˆ˜ìµì„ ë³´ì—¬ì¤ë‹ˆë‹¤
    - ë²”ë¡€ í•­ëª©ì„ í´ë¦­í•˜ì—¬ ì±„ë„ í‘œì‹œ/ìˆ¨ê¸°ê¸°
    """)
    
    st.markdown("---")
    
    # Weekly data table
    st.markdown("### Weekly Breakdown")
    
    # Format table for display
    display_decomp = decomp_filtered.copy()
    
    # Format numeric columns
    numeric_cols = display_decomp.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        display_decomp[col] = display_decomp[col].apply(lambda x: f"{x:,.0f}")
    
    st.dataframe(
        display_decomp,
        use_container_width=True,
        height=400
    )

# ============================================================================
# TAB 4: RESPONSE CURVES
# ============================================================================

with curve_tab:
    st.markdown("## ğŸ“‰ Response Curves")
    st.markdown("ì±„ë„ ê°„ ì§€ì¶œ ë°°ë¶„ì„ ìµœì í™”í•˜ì„¸ìš”")
    
    st.info("""
    **ë°˜ì‘ ê³¡ì„ ì´ ë³´ì—¬ì£¼ëŠ” ê²ƒ:**
    - ê° ì±„ë„ì˜ ì§€ì¶œì„ ë³€ê²½í•  ë•Œ ìˆ˜ìµì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€
    - ğŸ”´ **ë¹¨ê°„ ì **: í˜„ì¬ ì§€ì¶œ ìˆ˜ì¤€
    - ğŸŸ  **ì£¼í™© ë‹¤ì´ì•„ëª¬ë“œ**: í¬í™” ì§€ì  (í•œê³„ ROAS < 1)
    - ê³¡ì„  í˜•íƒœëŠ” ìˆ˜ìµ ì²´ê°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
    """)
    
    # Response curves
    fig_curves = cached_plot_response_curves(mmm, X, media_columns)
    st.plotly_chart(fig_curves, use_container_width=True)
    
    st.markdown("---")
    
    # Optimization recommendations
    st.markdown("### ğŸ’¡ Optimization Recommendations")
    
    st.markdown("#### Current Spend vs Optimal Spend")
    
    # Calculate optimal spend for each channel
    optimization_data = []
    
    for channel in media_columns:
        current_spend = X[channel].mean()
        
        # Generate response curve
        budget_range = np.linspace(0, current_spend * 2, 100)
        curve_df = mmm.get_response_curve(channel, budget_range, X)
        
        # Find optimal spend (where marginal ROAS = 2.0, or closest)
        target_roas = 2.0
        optimal_idx = (curve_df['marginal_roas'] - target_roas).abs().idxmin()
        optimal_spend = curve_df.loc[optimal_idx, 'spend']
        optimal_revenue = curve_df.loc[optimal_idx, 'revenue']
        
        # Current revenue
        current_idx = (curve_df['spend'] - current_spend).abs().idxmin()
        current_revenue = curve_df.loc[current_idx, 'revenue']
        current_marginal_roas = curve_df.loc[current_idx, 'marginal_roas']
        
        optimization_data.append({
            'Channel': channel,
            'Current Spend': current_spend,
            'Optimal Spend': optimal_spend,
            'Spend Change': optimal_spend - current_spend,
            'Spend Change %': ((optimal_spend - current_spend) / current_spend * 100) if current_spend > 0 else 0,
            'Current Marginal ROAS': current_marginal_roas,
            'Revenue Impact': optimal_revenue - current_revenue
        })
    
    opt_df = pd.DataFrame(optimization_data)
    
    # Format for display
    display_opt = opt_df.copy()
    display_opt['Current Spend'] = display_opt['Current Spend'].apply(lambda x: format_currency(x, decimals=0))
    display_opt['Optimal Spend'] = display_opt['Optimal Spend'].apply(lambda x: format_currency(x, decimals=0))
    display_opt['Spend Change'] = display_opt['Spend Change'].apply(lambda x: format_currency(x, decimals=0))
    display_opt['Spend Change %'] = display_opt['Spend Change %'].apply(lambda x: f"{x:+.1f}%")
    display_opt['Current Marginal ROAS'] = display_opt['Current Marginal ROAS'].apply(lambda x: f"{x:.2f}")
    display_opt['Revenue Impact'] = display_opt['Revenue Impact'].apply(lambda x: format_currency(x, decimals=0))
    
    st.dataframe(display_opt, use_container_width=True, hide_index=True)
    
    st.markdown("""
    **í•´ì„:**
    - **ì–‘ìˆ˜ ì§€ì¶œ ë³€í™”**: ì´ ì±„ë„ì˜ ì§€ì¶œ ì¦ê°€
    - **ìŒìˆ˜ ì§€ì¶œ ë³€í™”**: ì´ ì±„ë„ì˜ ì§€ì¶œ ê°ì†Œ
    - **ìˆ˜ìµ ì˜í–¥**: ìµœì í™”ë¡œ ì¸í•œ ì˜ˆìƒ ìˆ˜ìµ ë³€í™”
    """)

# ============================================================================
# TAB 5: MODEL DIAGNOSTICS
# ============================================================================

with diag_tab:
    st.markdown("## ğŸ” Model Diagnostics")
    st.markdown("ëª¨ë¸ ê°€ì •ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ê³ ê¸‰ ì§„ë‹¨")
    
    # Calculate residuals
    y_all = np.concatenate([y_train, y_test])
    y_pred_all = np.concatenate([y_train_pred, y_test_pred])
    residuals = y_all - y_pred_all
    
    # Q-Q Plot
    st.markdown("### Q-Q Plot (Normality Check)")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig_qq = cached_plot_qq(residuals)
        st.plotly_chart(fig_qq, use_container_width=True)
    
    with col2:
        st.markdown("#### í•´ì„")
        st.markdown("""
        **Q-Q í”Œë¡¯ì€ ì”ì°¨ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.**
        
        **ì¢‹ì€ ì‹ í˜¸:**
        - ì ë“¤ì´ ë¹¨ê°„ ì„ ì„ ë°€ì ‘í•˜ê²Œ ë”°ë¦„
        - ì²´ê³„ì ì¸ í¸ì°¨ê°€ ì—†ìŒ
        
        **ê²½ê³  ì‹ í˜¸:**
        - Sì í˜•íƒœì˜ íŒ¨í„´ (ë‘êº¼ìš´ ê¼¬ë¦¬)
        - ì„ ìœ¼ë¡œë¶€í„° ì²´ê³„ì ì¸ í¸ì°¨
        """)
    
    st.markdown("---")
    
    # Statistical tests
    st.markdown("### Statistical Tests")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Shapiro-Wilk test for normality
        from scipy.stats import shapiro
        stat, p_value = shapiro(residuals[:min(5000, len(residuals))])  # Limit sample size
        
        st.metric(
            "Shapiro-Wilk ê²€ì •",
            f"p = {p_value:.4f}",
            help="ì”ì°¨ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ëŠ”ì§€ ê²€ì •í•©ë‹ˆë‹¤. p > 0.05ì´ë©´ ì •ê·œì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
        )
        
        if p_value > 0.05:
            st.success("âœ… ì”ì°¨ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„")
        else:
            st.warning("âš ï¸ ì”ì°¨ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŒ")
    
    with col2:
        # Mean of residuals (should be close to 0)
        mean_residual = residuals.mean()
        
        st.metric(
            "í‰ê·  ì”ì°¨",
            f"{mean_residual:,.2f}",
            help="0ì— ê°€ê¹Œì›Œì•¼ í•©ë‹ˆë‹¤. í° ê°’ì€ í¸í–¥ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
        )
        
        if abs(mean_residual) < residuals.std() * 0.1:
            st.success("âœ… í¸í–¥ë˜ì§€ ì•Šì€ ì˜ˆì¸¡")
        else:
            st.warning("âš ï¸ ëª¨ë¸ì´ í¸í–¥ë  ìˆ˜ ìˆìŒ")
    
    with col3:
        # Std of residuals
        std_residual = residuals.std()
        
        st.metric(
            "ì”ì°¨ í‘œì¤€í¸ì°¨",
            format_currency(std_residual, decimals=0),
            help="ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±ì˜ ì²™ë„"
        )
    
    st.markdown("---")
    
    # Model coefficients
    st.markdown("### Model Coefficients")
    
    summary = mmm.get_model_summary()
    coef_df = pd.DataFrame([
        {'Feature': k, 'Coefficient': v}
        for k, v in summary['coefficients'].items()
    ])
    
    # Sort by absolute coefficient
    coef_df['Abs_Coef'] = coef_df['Coefficient'].abs()
    coef_df = coef_df.sort_values('Abs_Coef', ascending=False)
    coef_df = coef_df.drop('Abs_Coef', axis=1)
    
    # Format
    coef_df['Coefficient'] = coef_df['Coefficient'].apply(lambda x: f"{x:.4f}")
    
    st.dataframe(coef_df, use_container_width=True, hide_index=True)
    
    st.info("""
    **ê³„ìˆ˜ê°€ ë‚˜íƒ€ë‚´ëŠ” ê²ƒ:**
    - ê° ê¸°ëŠ¥ì´ ìˆ˜ìµì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ìŠ¤ì¼€ì¼ë§ ë° ë³€í™˜ í›„)
    - ì ˆëŒ€ê°’ì´ í´ìˆ˜ë¡ = ì˜í–¥ë ¥ì´ ê°•í•¨
    - ë¶€í˜¸ëŠ” íš¨ê³¼ì˜ ë°©í–¥ì„ ë‚˜íƒ€ëƒ„
    """)
    
    st.markdown("---")
    
    # Overall assessment
    st.markdown("### ğŸ¯ Overall Model Assessment")
    
    # Calculate assessment score
    assessment_score = 0
    issues = []
    strengths = []
    
    # Check RÂ²
    if test_metrics['r2'] > 0.8:
        assessment_score += 2
        strengths.append("ìš°ìˆ˜í•œ ì˜ˆì¸¡ë ¥ (RÂ² > 0.8)")
    elif test_metrics['r2'] > 0.6:
        assessment_score += 1
        strengths.append("ì–‘í˜¸í•œ ì˜ˆì¸¡ë ¥ (RÂ² > 0.6)")
    else:
        issues.append("ë‚®ì€ RÂ²ëŠ” ë¶€ì í•©ì„ ì‹œì‚¬í•¨")
    
    # Check MAPE
    if test_metrics['mape'] < 10:
        assessment_score += 2
        strengths.append("ë§¤ìš° ì •í™•í•œ ì˜ˆì¸¡ (MAPE < 10%)")
    elif test_metrics['mape'] < 20:
        assessment_score += 1
        strengths.append("í•©ë¦¬ì ì¸ ì •í™•ë„ (MAPE < 20%)")
    else:
        issues.append("ë†’ì€ MAPEëŠ” í° ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ì‹œì‚¬í•¨")
    
    # Check residual normality
    if p_value > 0.05:
        assessment_score += 1
        strengths.append("ì”ì°¨ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¦„")
    else:
        issues.append("ì”ì°¨ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŒ")
    
    # Check bias
    if abs(mean_residual) < residuals.std() * 0.1:
        assessment_score += 1
        strengths.append("ì˜ˆì¸¡ì´ í¸í–¥ë˜ì§€ ì•ŠìŒ")
    else:
        issues.append("ëª¨ë¸ì´ ì¼ë¶€ í¸í–¥ì„ ë³´ì„")
    
    # Display assessment
    if assessment_score >= 5:
        st.success("âœ… **ìš°ìˆ˜í•œ ëª¨ë¸ í’ˆì§ˆ**")
    elif assessment_score >= 3:
        st.info("âœ“ **ì–‘í˜¸í•œ ëª¨ë¸ í’ˆì§ˆ**")
    else:
        st.warning("âš ï¸ **ëª¨ë¸ ê°œì„  í•„ìš”**")
    
    if strengths:
        st.markdown("**ê°•ì :**")
        for strength in strengths:
            st.markdown(f"- âœ… {strength}")
    
    if issues:
        st.markdown("**ê°œì„  ì˜ì—­:**")
        for issue in issues:
            st.markdown(f"- âš ï¸ {issue}")

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem 0;">
    <p>Ridge MMM Results Dashboard â€¢ Built with Streamlit & Plotly</p>
</div>
""", unsafe_allow_html=True)
